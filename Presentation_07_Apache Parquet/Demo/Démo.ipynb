{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc74d06-967e-4440-af80-d5e2931dd12c",
   "metadata": {},
   "source": [
    "### Installation et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b460356c-19c9-4bad-8a72-dd423c9481e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démonstration Parquet Simplifiée - NYC Taxi Data\n"
     ]
    }
   ],
   "source": [
    "# Requirements d'installation\n",
    "# pip install pandas pyarrow fastparquet\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Démonstration Parquet Simplifiée - NYC Taxi Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2146148-e871-4fa7-977c-9540c086e09a",
   "metadata": {},
   "source": [
    "### Fonctions de Téléchargement et Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6300a56-e339-4aed-b4f6-f9a817495a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_taxi_data():\n",
    "    \"\"\"Télécharge les données NYC Taxi 2025 ou crée des données simulées\"\"\"\n",
    "    \n",
    "    # URLs des données NYC Taxi 2025\n",
    "    urls_2025 = [\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet\",\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-12.parquet\",\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-11.parquet\"\n",
    "    ]\n",
    "    \n",
    "    for url in urls_2025:\n",
    "        try:\n",
    "            print(f\"📥 Tentative de téléchargement: {url.split('/')[-1]}\")\n",
    "            df = pd.read_parquet(url)\n",
    "            print(f\"Données téléchargées: {len(df):,} lignes\")\n",
    "            return df.head(50000)  # Limiter pour la démo\n",
    "        except Exception as e:\n",
    "            print(f\" Erreur: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"Tous les téléchargements ont échoué, création de données simulées...\")\n",
    "    return create_simulated_taxi_data()\n",
    "\n",
    "def create_simulated_taxi_data(n_rows=50000):\n",
    "    \"\"\"Crée des données de taxi simulées NYC style\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'tpep_pickup_datetime': pd.date_range('2025-01-01', periods=n_rows, freq='1min'),\n",
    "        'tpep_dropoff_datetime': pd.date_range('2025-01-01 00:10:00', periods=n_rows, freq='1min'),\n",
    "        'passenger_count': np.random.choice([1, 2, 3, 4, 5], n_rows, p=[0.5, 0.3, 0.1, 0.05, 0.05]),\n",
    "        'trip_distance': np.random.exponential(2.5, n_rows),\n",
    "        'fare_amount': np.random.gamma(2, 5, n_rows),\n",
    "        'extra': np.random.choice([0, 0.5, 1], n_rows, p=[0.7, 0.2, 0.1]),\n",
    "        'tip_amount': np.random.gamma(1, 2, n_rows),\n",
    "        'total_amount': np.random.gamma(3, 7, n_rows),\n",
    "        'pickup_location_id': np.random.randint(1, 265, n_rows),\n",
    "        'dropoff_location_id': np.random.randint(1, 265, n_rows),\n",
    "        'payment_type': np.random.choice([1, 2, 3, 4], n_rows, p=[0.6, 0.3, 0.05, 0.05])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['total_amount'] = df['fare_amount'] + df['tip_amount'] + df['extra']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afb1da-9731-437e-9e73-64744e63eb73",
   "metadata": {},
   "source": [
    "### Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda8b027-b81e-4c12-b1fb-e3bf6e4ea1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Tentative de téléchargement: yellow_tripdata_2025-01.parquet\n",
      "Données téléchargées: 3,475,226 lignes\n",
      "📊 Dataset: 50,000 lignes, 20 colonnes\n",
      "\n",
      "📋 Aperçu des données:\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         1  2025-01-01 00:18:38   2025-01-01 00:26:59              1.0   \n",
      "1         1  2025-01-01 00:32:40   2025-01-01 00:35:13              1.0   \n",
      "2         1  2025-01-01 00:44:04   2025-01-01 00:46:01              1.0   \n",
      "3         2  2025-01-01 00:14:27   2025-01-01 00:20:01              3.0   \n",
      "4         2  2025-01-01 00:21:34   2025-01-01 00:25:06              3.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.60         1.0                  N           229           237   \n",
      "1           0.50         1.0                  N           236           237   \n",
      "2           0.60         1.0                  N           141           141   \n",
      "3           0.52         1.0                  N           244           244   \n",
      "4           0.66         1.0                  N           244           116   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         10.0    3.5      0.5        3.00           0.0   \n",
      "1             1          5.1    3.5      0.5        2.02           0.0   \n",
      "2             1          5.1    3.5      0.5        2.00           0.0   \n",
      "3             2          7.2    1.0      0.5        0.00           0.0   \n",
      "4             2          5.8    1.0      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
      "0                    1.0         18.00                   2.5          0.0   \n",
      "1                    1.0         12.12                   2.5          0.0   \n",
      "2                    1.0         12.10                   2.5          0.0   \n",
      "3                    1.0          9.70                   0.0          0.0   \n",
      "4                    1.0          8.30                   0.0          0.0   \n",
      "\n",
      "   cbd_congestion_fee  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "\n",
      "📊 Info sur le dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               50000 non-null  int32         \n",
      " 1   tpep_pickup_datetime   50000 non-null  datetime64[us]\n",
      " 2   tpep_dropoff_datetime  50000 non-null  datetime64[us]\n",
      " 3   passenger_count        50000 non-null  float64       \n",
      " 4   trip_distance          50000 non-null  float64       \n",
      " 5   RatecodeID             50000 non-null  float64       \n",
      " 6   store_and_fwd_flag     50000 non-null  object        \n",
      " 7   PULocationID           50000 non-null  int32         \n",
      " 8   DOLocationID           50000 non-null  int32         \n",
      " 9   payment_type           50000 non-null  int64         \n",
      " 10  fare_amount            50000 non-null  float64       \n",
      " 11  extra                  50000 non-null  float64       \n",
      " 12  mta_tax                50000 non-null  float64       \n",
      " 13  tip_amount             50000 non-null  float64       \n",
      " 14  tolls_amount           50000 non-null  float64       \n",
      " 15  improvement_surcharge  50000 non-null  float64       \n",
      " 16  total_amount           50000 non-null  float64       \n",
      " 17  congestion_surcharge   50000 non-null  float64       \n",
      " 18  Airport_fee            50000 non-null  float64       \n",
      " 19  cbd_congestion_fee     50000 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(13), int32(3), int64(1), object(1)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "taxi_df = download_taxi_data()\n",
    "print(f\"📊 Dataset: {taxi_df.shape[0]:,} lignes, {taxi_df.shape[1]} colonnes\")\n",
    "\n",
    "# Aperçu des données\n",
    "print(\"\\n📋 Aperçu des données:\")\n",
    "print(taxi_df.head())\n",
    "print(f\"\\n📊 Info sur le dataset:\")\n",
    "print(taxi_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a494428-8711-41c2-beaf-9a87d323cb40",
   "metadata": {},
   "source": [
    "### Sauvegarde en Différents Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fa77a1-b411-4a17-bb8a-640e4acc9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "💾 SAUVEGARDE EN DIFFÉRENTS FORMATS\n",
      "============================================================\n",
      "📄 Sauvegarde CSV...\n",
      "📦 Sauvegarde Parquet (sans compression)...\n",
      "📦 Sauvegarde Parquet (Snappy)...\n",
      "📦 Sauvegarde Parquet (Gzip)...\n",
      "✅ Toutes les sauvegardes terminées!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"💾 SAUVEGARDE EN DIFFÉRENTS FORMATS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CSV\n",
    "print(\"📄 Sauvegarde CSV...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_csv(\"taxi_data.csv\", index=False)\n",
    "csv_time = time.time() - start_time\n",
    "csv_size = os.path.getsize(\"taxi_data.csv\") / 1024**2\n",
    "\n",
    "# Parquet avec différentes compressions\n",
    "print(\"📦 Sauvegarde Parquet (sans compression)...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_parquet(\"taxi_data_none.parquet\", compression=None)\n",
    "parquet_none_time = time.time() - start_time\n",
    "parquet_none_size = os.path.getsize(\"taxi_data_none.parquet\") / 1024**2\n",
    "\n",
    "print(\"📦 Sauvegarde Parquet (Snappy)...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_parquet(\"taxi_data_snappy.parquet\", compression='snappy')\n",
    "parquet_snappy_time = time.time() - start_time\n",
    "parquet_snappy_size = os.path.getsize(\"taxi_data_snappy.parquet\") / 1024**2\n",
    "\n",
    "print(\"📦 Sauvegarde Parquet (Gzip)...\")\n",
    "start_time = time.time()\n",
    "taxi_df.to_parquet(\"taxi_data_gzip.parquet\", compression='gzip')\n",
    "parquet_gzip_time = time.time() - start_time\n",
    "parquet_gzip_size = os.path.getsize(\"taxi_data_gzip.parquet\") / 1024**2\n",
    "\n",
    "print(\"✅ Toutes les sauvegardes terminées!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535b366-4da6-4fb0-9077-c2305e8d58f9",
   "metadata": {},
   "source": [
    "### Comparaison des Tailles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3240218e-deb4-4895-b8b9-c7a13ad2a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📏 COMPARAISON DES TAILLES\n",
      "============================================================\n",
      "Format                | Taille (MB)  | Ratio vs CSV\n",
      "-----------------------------------------------------------------\n",
      "CSV                   |      5.3     | 1.0x\n",
      "Parquet (aucune)      |      1.2     | 4.3x\n",
      "Parquet (Snappy)      |      1.1     | 5.0x\n",
      "Parquet (Gzip)        |      0.8     | 6.2x\n",
      "\n",
      "🏆 Meilleure compression: 6.2x plus compact\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📏 COMPARAISON DES TAILLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Format                | Taille (MB)  | Ratio vs CSV\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"CSV                   | {csv_size:8.1f}     | 1.0x\")\n",
    "print(f\"Parquet (aucune)      | {parquet_none_size:8.1f}     | {csv_size/parquet_none_size:.1f}x\")\n",
    "print(f\"Parquet (Snappy)      | {parquet_snappy_size:8.1f}     | {csv_size/parquet_snappy_size:.1f}x\")\n",
    "print(f\"Parquet (Gzip)        | {parquet_gzip_size:8.1f}     | {csv_size/parquet_gzip_size:.1f}x\")\n",
    "\n",
    "print(f\"\\n🏆 Meilleure compression: {csv_size/min(parquet_none_size, parquet_snappy_size, parquet_gzip_size):.1f}x plus compact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3680c-6b52-44b8-85b7-5640c0838f96",
   "metadata": {},
   "source": [
    "### Performance de Lecture Complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d952e64b-9135-411d-adce-5847e3fccc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "⚡ PERFORMANCE DE LECTURE\n",
      "============================================================\n",
      "📖 Test lecture CSV...\n",
      "📖 Test lecture Parquet...\n",
      "\n",
      "Format    | Temps lecture | Lignes\n",
      "----------------------------------------\n",
      "CSV       |     0.49s     | 50,000\n",
      "Parquet   |     0.04s     | 50,000\n",
      "\n",
      "🚀 Parquet est 11.9x plus rapide pour la lecture\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"⚡ PERFORMANCE DE LECTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Lecture complète CSV\n",
    "print(\"📖 Test lecture CSV...\")\n",
    "start_time = time.time()\n",
    "df_csv = pd.read_csv(\"taxi_data.csv\")\n",
    "csv_read_time = time.time() - start_time\n",
    "\n",
    "# Lecture complète Parquet\n",
    "print(\"📖 Test lecture Parquet...\")\n",
    "start_time = time.time()\n",
    "df_parquet = pd.read_parquet(\"taxi_data_snappy.parquet\")\n",
    "parquet_read_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nFormat    | Temps lecture | Lignes\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"CSV       | {csv_read_time:8.2f}s     | {len(df_csv):,}\")\n",
    "print(f\"Parquet   | {parquet_read_time:8.2f}s     | {len(df_parquet):,}\")\n",
    "print(f\"\\n🚀 Parquet est {csv_read_time/parquet_read_time:.1f}x plus rapide pour la lecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85c7ee-95dd-4f99-8d70-603f77e10e9c",
   "metadata": {},
   "source": [
    "### Performance de Filtrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce51be4-4e42-4633-baab-ea774b939fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔍 PERFORMANCE DE FILTRAGE\n",
      "============================================================\n",
      "🎯 Test: Courses avec total_amount > 20$\n",
      "\n",
      "Méthode           | Temps    | Lignes résultat\n",
      "---------------------------------------------\n",
      "CSV (full+filter) |   0.49s | 25,095\n",
      "Parquet (filter)  |   0.03s | 25,095\n",
      "\n",
      "🚀 Parquet filtrage est 15.7x plus rapide\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔍 PERFORMANCE DE FILTRAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test: Courses avec montant > 20$\n",
    "print(\"🎯 Test: Courses avec total_amount > 20$\")\n",
    "\n",
    "# Filtrage CSV (lecture complète puis filtrage)\n",
    "start_time = time.time()\n",
    "df_csv_full = pd.read_csv(\"taxi_data.csv\")\n",
    "df_csv_filtered = df_csv_full[df_csv_full['total_amount'] > 20]\n",
    "csv_filter_time = time.time() - start_time\n",
    "\n",
    "# Filtrage Parquet (avec predicate pushdown)\n",
    "start_time = time.time()\n",
    "df_parquet_filtered = pd.read_parquet(\"taxi_data_snappy.parquet\", \n",
    "                                     filters=[('total_amount', '>', 20)])\n",
    "parquet_filter_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nMéthode           | Temps    | Lignes résultat\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"CSV (full+filter) | {csv_filter_time:6.2f}s | {len(df_csv_filtered):,}\")\n",
    "print(f\"Parquet (filter)  | {parquet_filter_time:6.2f}s | {len(df_parquet_filtered):,}\")\n",
    "print(f\"\\n🚀 Parquet filtrage est {csv_filter_time/parquet_filter_time:.1f}x plus rapide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536740c2-d88a-4ae3-97c0-87abbb4a797a",
   "metadata": {},
   "source": [
    "### Performance de Lecture par Colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed43c52f-05f5-435b-aaf9-b3663b73f03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Test: Lecture colonnes spécifiques\n",
      "\n",
      "Méthode           | Temps    | Colonnes\n",
      "----------------------------------------\n",
      "CSV colonnes      |   0.35s | 3\n",
      "Parquet colonnes  |   0.01s | 3\n",
      "\n",
      "🚀 Parquet colonnes est 24.2x plus rapide\n",
      "\n",
      "📋 Aperçu des colonnes lues:\n",
      "  tpep_pickup_datetime  passenger_count  total_amount\n",
      "0  2025-01-01 00:18:38              1.0         18.00\n",
      "1  2025-01-01 00:32:40              1.0         12.12\n",
      "2  2025-01-01 00:44:04              1.0         12.10\n",
      "3  2025-01-01 00:14:27              3.0          9.70\n",
      "4  2025-01-01 00:21:34              3.0          8.30\n"
     ]
    }
   ],
   "source": [
    "# Test: Lecture colonnes spécifiques\n",
    "print(f\"\\n🎯 Test: Lecture colonnes spécifiques\")\n",
    "columns_to_read = ['tpep_pickup_datetime', 'passenger_count', 'total_amount']\n",
    "\n",
    "# CSV - colonnes spécifiques\n",
    "start_time = time.time()\n",
    "df_csv_cols = pd.read_csv(\"taxi_data.csv\", usecols=columns_to_read)\n",
    "csv_cols_time = time.time() - start_time\n",
    "\n",
    "# Parquet - colonnes spécifiques\n",
    "start_time = time.time()\n",
    "df_parquet_cols = pd.read_parquet(\"taxi_data_snappy.parquet\", columns=columns_to_read)\n",
    "parquet_cols_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nMéthode           | Temps    | Colonnes\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"CSV colonnes      | {csv_cols_time:6.2f}s | {len(df_csv_cols.columns)}\")\n",
    "print(f\"Parquet colonnes  | {parquet_cols_time:6.2f}s | {len(df_parquet_cols.columns)}\")\n",
    "print(f\"\\n🚀 Parquet colonnes est {csv_cols_time/parquet_cols_time:.1f}x plus rapide\")\n",
    "\n",
    "# Aperçu des données lues\n",
    "print(f\"\\n📋 Aperçu des colonnes lues:\")\n",
    "print(df_parquet_cols.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5829c3c-70bf-45ca-a4cd-6000a8ac9d93",
   "metadata": {},
   "source": [
    " ### Métadonnées Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e55c18-3d4f-45a5-8d4f-2dc21f35d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📋 MÉTADONNÉES PARQUET\n",
      "============================================================\n",
      "🔍 INFORMATIONS GÉNÉRALES:\n",
      "  Nombre de lignes: 50,000\n",
      "  Nombre de colonnes: 20\n",
      "  Nombre de row groups: 1\n",
      "  Taille fichier: 1.1 MB\n",
      "  Compression: SNAPPY\n",
      "\n",
      "📊 SCHEMA DES COLONNES:\n",
      "  VendorID                  | int32\n",
      "  tpep_pickup_datetime      | timestamp[us]\n",
      "  tpep_dropoff_datetime     | timestamp[us]\n",
      "  passenger_count           | double\n",
      "  trip_distance             | double\n",
      "  RatecodeID                | double\n",
      "  store_and_fwd_flag        | string\n",
      "  PULocationID              | int32\n",
      "  DOLocationID              | int32\n",
      "  payment_type              | int64\n",
      "  fare_amount               | double\n",
      "  extra                     | double\n",
      "  mta_tax                   | double\n",
      "  tip_amount                | double\n",
      "  tolls_amount              | double\n",
      "  improvement_surcharge     | double\n",
      "  total_amount              | double\n",
      "  congestion_surcharge      | double\n",
      "  Airport_fee               | double\n",
      "  cbd_congestion_fee        | double\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📋 MÉTADONNÉES PARQUET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ouvrir le fichier Parquet\n",
    "parquet_file = pq.ParquetFile(\"taxi_data_snappy.parquet\")\n",
    "\n",
    "print(\"🔍 INFORMATIONS GÉNÉRALES:\")\n",
    "print(f\"  Nombre de lignes: {parquet_file.metadata.num_rows:,}\")\n",
    "print(f\"  Nombre de colonnes: {parquet_file.metadata.num_columns}\")\n",
    "print(f\"  Nombre de row groups: {parquet_file.metadata.num_row_groups}\")\n",
    "print(f\"  Taille fichier: {os.path.getsize('taxi_data_snappy.parquet') / 1024**2:.1f} MB\")\n",
    "print(f\"  Compression: {parquet_file.metadata.row_group(0).column(0).compression}\")\n",
    "\n",
    "print(f\"\\n📊 SCHEMA DES COLONNES:\")\n",
    "schema = parquet_file.schema_arrow\n",
    "for i, field in enumerate(schema):\n",
    "    print(f\"  {field.name:25} | {field.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf8580-06d3-4636-b0f6-e6e90a0ccea9",
   "metadata": {},
   "source": [
    "### Statistiques des Colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c399deb7-cb9d-4f39-b888-d30d91bef4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📈 STATISTIQUES PAR COLONNE\n",
      "============================================================\n",
      "🔢 STATISTIQUES AUTOMATIQUES:\n",
      "\n",
      "📊 VendorID:\n",
      "  Type Arrow: int32\n",
      "  Type physique: INT32\n",
      "  Compression: SNAPPY\n",
      "  Taille compressée: 9,871 bytes\n",
      "  Taille non-compressée: 11,538 bytes\n",
      "  Minimum: 1\n",
      "  Maximum: 7\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "📊 tpep_pickup_datetime:\n",
      "  Type Arrow: timestamp[us]\n",
      "  Type physique: INT64\n",
      "  Compression: SNAPPY\n",
      "  Taille compressée: 280,822 bytes\n",
      "  Taille non-compressée: 337,738 bytes\n",
      "  Minimum: 2024-12-31 20:47:55\n",
      "  Maximum: 2025-01-01 17:02:00\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "📊 tpep_dropoff_datetime:\n",
      "  Type Arrow: timestamp[us]\n",
      "  Type physique: INT64\n",
      "  Compression: SNAPPY\n",
      "  Taille compressée: 284,866 bytes\n",
      "  Taille non-compressée: 339,850 bytes\n",
      "  Minimum: 2024-12-31 20:54:00\n",
      "  Maximum: 2025-01-02 16:37:05\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "📊 passenger_count:\n",
      "  Type Arrow: double\n",
      "  Type physique: DOUBLE\n",
      "  Compression: SNAPPY\n",
      "  Taille compressée: 18,185 bytes\n",
      "  Taille non-compressée: 24,065 bytes\n",
      "  Minimum: -0.0\n",
      "  Maximum: 9.0\n",
      "  Valeurs nulles: 0\n",
      "\n",
      "📊 trip_distance:\n",
      "  Type Arrow: double\n",
      "  Type physique: DOUBLE\n",
      "  Compression: SNAPPY\n",
      "  Taille compressée: 84,737 bytes\n",
      "  Taille non-compressée: 93,499 bytes\n",
      "  Minimum: -0.0\n",
      "  Maximum: 133.3\n",
      "  Valeurs nulles: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📈 STATISTIQUES PAR COLONNE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques du premier row group\n",
    "rg_metadata = parquet_file.metadata.row_group(0)\n",
    "schema_fields = parquet_file.schema_arrow\n",
    "\n",
    "print(\"🔢 STATISTIQUES AUTOMATIQUES:\")\n",
    "for i in range(min(5, rg_metadata.num_columns)):  # Limiter à 5 colonnes\n",
    "    col_metadata = rg_metadata.column(i)\n",
    "    stats = col_metadata.statistics\n",
    "    field_name = schema_fields[i].name\n",
    "    field_type = schema_fields[i].type\n",
    "    \n",
    "    print(f\"\\n📊 {col_metadata.path_in_schema}:\")\n",
    "    print(f\"  Type Arrow: {field_type}\")\n",
    "    print(f\"  Type physique: {col_metadata.physical_type}\")\n",
    "    print(f\"  Compression: {col_metadata.compression}\")\n",
    "    print(f\"  Taille compressée: {col_metadata.total_compressed_size:,} bytes\")\n",
    "    print(f\"  Taille non-compressée: {col_metadata.total_uncompressed_size:,} bytes\")\n",
    "    \n",
    "    if stats:\n",
    "        if stats.has_min_max:\n",
    "            print(f\"  Minimum: {stats.min}\")\n",
    "            print(f\"  Maximum: {stats.max}\")\n",
    "        print(f\"  Valeurs nulles: {stats.null_count:,}\")\n",
    "        if stats.distinct_count:\n",
    "            print(f\"  Valeurs distinctes: {stats.distinct_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20349e0f-6d50-46d8-94c2-1e0b44c779b8",
   "metadata": {},
   "source": [
    "### Résumé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaceca05-4def-496e-bfd1-183b6817f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎯 RÉSUMÉ\n",
      "============================================================\n",
      "✅ AVANTAGES PARQUET DÉMONTRÉS:\n",
      "  📦 Compression: 5.0x plus compact que CSV\n",
      "  ⚡ Lecture: 11.9x plus rapide que CSV\n",
      "  🔍 Filtrage: 15.7x plus rapide avec prédicats\n",
      "  📊 Colonnes: 24.2x plus rapide pour lecture sélective\n",
      "  📋 Métadonnées: Schema automatique, statistiques, compression\n",
      "\n",
      "🎉 Démonstration terminée!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎯 RÉSUMÉ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"✅ AVANTAGES PARQUET DÉMONTRÉS:\")\n",
    "print(f\"  📦 Compression: {csv_size/parquet_snappy_size:.1f}x plus compact que CSV\")\n",
    "print(f\"  ⚡ Lecture: {csv_read_time/parquet_read_time:.1f}x plus rapide que CSV\")\n",
    "print(f\"  🔍 Filtrage: {csv_filter_time/parquet_filter_time:.1f}x plus rapide avec prédicats\")\n",
    "print(f\"  📊 Colonnes: {csv_cols_time/parquet_cols_time:.1f}x plus rapide pour lecture sélective\")\n",
    "print(\"  📋 Métadonnées: Schema automatique, statistiques, compression\")\n",
    "\n",
    "print(\"\\n🎉 Démonstration terminée!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa75ee8-ea3a-4f3e-b339-a65bf69860dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
